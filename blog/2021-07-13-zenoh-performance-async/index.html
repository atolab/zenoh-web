<!doctype html><html lang=en><head><link rel=apple-touch-icon sizes=180x180 href=../../apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=../../favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=../../favicon-16x16.png><link rel=manifest href=../../site.webmanifest><link rel=mask-icon href=../../safari-pinned-tab.png color=#7da7d8><meta name=msapplication-TileColor content="#7da7d8"><meta name=theme-color content="#7da7d8"><meta charset=utf-8><meta name=description content="Eclipse Zenoh, unify data in motion, data at rest and computations."><meta name=keywords content="pub/sub,query,geo distributed storage,Rust,protocol,DDS,MQTT,Edge,IoT,MEC"><meta name=author content="The Zenoh Team"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta http-equiv=x-ua-compatible content="ie=edge"><link rel=stylesheet href=../../css/bootstrap-reboot.css><link rel=stylesheet href=../../css/bootstrap.css><link rel=stylesheet href=../../css/font-awesome.min.css><link rel=stylesheet href=../../css/ato.css><link rel=stylesheet href=../../css/syntax.css><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css><link rel=alternate type=application/rss+xml href=../../blog/index.xml><title>Zenoh performance: a stroll in Rust async wonderland · zenoh - pub/sub, geo distributed storage, query</title></head><body><header class="navbar navbar-expand navbar-dark flex-column flex-md-row ato-navbar"><a class=navbar-brand href=../../><img src=../../img/zenoh-dragon-bg.png class=align-middle alt></a><div class="collapse navbar-collapse"><ul class=navbar-nav><li class=nav-item><a class=nav-link href=../../>Home</a></li><li class=nav-item><a class=nav-link href=../../docs/getting-started/key-concepts/>Documentation</a></li><li class=nav-item><a class=nav-link href=../../community/>Community</a></li><li class=nav-item><a class="nav-link active" href=../../blog/2021-07-13-zenoh-performance-async/>Blog</a></li></ul></div><ul class="navbar-nav flex-row ml-md-auto d-none d-md-flex"><li class=nav-item><a class="nav-link p-2" href=https://github.com/eclipse-zenoh/zenoh target=_blank rel=noopener aria-label=GitHub><svg class="navbar-nav-svg" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 512 499.36" focusable="false"><title>GitHub</title><path d="M256 0C114.64.0.0 114.61.0 256c0 113.09 73.34 209 175.08 242.9 12.8 2.35 17.47-5.56 17.47-12.34.0-6.08-.22-22.18-.35-43.54-71.2 15.49-86.2-34.34-86.2-34.34-11.64-29.57-28.42-37.45-28.42-37.45-23.27-15.84 1.73-15.55 1.73-15.55 25.69 1.81 39.21 26.38 39.21 26.38 22.84 39.12 59.92 27.82 74.5 21.27 2.33-16.54 8.94-27.82 16.25-34.22-56.84-6.43-116.6-28.43-116.6-126.49.0-27.95 10-50.8 26.35-68.69-2.63-6.48-11.42-32.5 2.51-67.75.0.0 21.49-6.88 70.4 26.24a242.65 242.65.0 01128.18.0c48.87-33.13 70.33-26.24 70.33-26.24 14 35.25 5.18 61.27 2.55 67.75 16.41 17.9 26.31 40.75 26.31 68.69.0 98.35-59.85 120-116.88 126.32 9.19 7.9 17.38 23.53 17.38 47.41.0 34.22-.31 61.83-.31 70.23.0 6.85 4.61 14.81 17.6 12.31C438.72 464.97 512 369.08 512 256.02 512 114.62 397.37.0 256 0z" fill="currentcolor" fill-rule="evenodd"/></svg></a></li><li class=nav-item><a class="nav-link p-2" href=https://twitter.com/atolab_ target=_blank rel=noopener aria-label=Twitter><svg class="navbar-nav-svg" xmlns="http://www.w3.org/2000/svg" viewbox="0 0 512 416.32" focusable="false"><title>Twitter</title><path d="M160.83 416.32c193.2.0 298.92-160.22 298.92-298.92.0-4.51.0-9-.2-13.52A214 214 0 00512 49.38a212.93 212.93.0 01-60.44 16.6 105.7 105.7.0 0046.3-58.19 209 209 0 01-66.79 25.37 105.09 105.09.0 00-181.73 71.91 116.12 116.12.0 002.66 24c-87.28-4.3-164.73-46.3-216.56-109.82A105.48 105.48.0 0068 159.6a106.27 106.27.0 01-47.53-13.11v1.43a105.28 105.28.0 0084.21 103.06 105.67 105.67.0 01-47.33 1.84 105.06 105.06.0 0098.14 72.94A210.72 210.72.0 0125 370.84a202.17 202.17.0 01-25-1.43 298.85 298.85.0 00160.83 46.92" fill="currentcolor"/></svg></a></li><li class=nav-item><a class="nav-link p-2" href=https://gitter.im/atolab/zenoh target=_blank rel=noopener aria-label=Gitter><svg class="navbar-nav-svg" xmlns="http://www.w3.org/2000/svg" focusable="false"><title>Gitter</title><path fill="currentcolor" d="M8.501 4.001H10.5V24H8.501V4.001zm6.999.0V24h-2V4.001h2zM3.5.0h2.001v15H3.5V0zm15 4.001h2V15h-2V4.001z"/></svg></a></li></ul><script async src="https://www.googletagmanager.com/gtag/js?id=UA-120904581-1"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments);}
gtag('js',new Date());gtag('config','UA-41082619-2');</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":""},"articleSection":"blog","name":"Zenoh performance: a stroll in Rust async wonderland","headline":"Zenoh performance: a stroll in Rust async wonderland","datePublished":"2021-07-13 00:00:00 \x2b0000 UTC","dateModified":"2021-07-13 00:00:00 \x2b0000 UTC","url":"\/blog\/2021-07-13-zenoh-performance-async\/","inLanguage":"en-US","author":"","creator":"","publisher":"","accountablePerson":"","copyrightHolder":"","copyrightYear":"13137","wordCount":"2046","keywords":[],"description":"13 July 2021 -- Paris."}</script></header><div class="container-fluid ato-blog"><div class="row flex-xl-nowrap"><div class="col-12 col-md-3 col-xl-2 ato-sidebar"><div class="ato-docs-toggle d-md-none p-0 d-flex ml-3 collapsed align-item-center"><h1 class=ato-title>Zenoh performance: a stroll in Rust async wonderland</h1><button class="btn btn-link" type=button data-toggle=collapse data-target=#ato-docs-nav aria-controls=ato-docs-nav aria-expanded=false aria-label="Toggle docs navigation"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 30 30" width="30" height="30" focusable="false"><title>Menu</title><path stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-miterlimit="10" d="M4 7h22M4 15h22M4 23h22"/></svg></button></div><nav class="ato-links collapse" id=ato-docs-nav><div class="ato-toc-item active"><p class=ato-toc-link>Blog Posts</p><ul class="nav ato-sidenav"><li><a href=../../blog/2021-07-13-zenoh-performance-async/ class=active>Zenoh performance: a stroll in Rust async wonderland</a></li><li><a href=../../blog/2021-07-05-zenoh-overhead/>Zenoh overhead: a story from our community</a></li><li><a href=../../blog/2021-06-14-zenoh-reliability/>Zenoh Reliability, Scalability and Congestion Control</a></li><li><a href=../../blog/2021-04-28-ros2-integration/>Integrating ROS2 with Eclipse zenoh</a></li><li><a href=../../blog/2021-03-23-discovery/>Minimizing Discovery Overhead in ROS2</a></li><li><a href=../../blog/2020-10-08-aithusa/>Zenoh Aithusa Hatched Out!</a></li><li><a href=../../blog/2020-06-29-zenoh-tidings/>Zenoh Tidings</a></li><li><a href=../../blog/2020-01-01-zenohtude/>A Year Full of Zenoh</a></li></ul></div></nav></div><div class="d-none d-xl-block col-xl-2 ato-toc"><div class=section-nav><nav id=TableOfContents><ul><li><a href=#peer-to-peer-communication>Peer-to-peer communication</a><ul><li><a href=#throughput>Throughput</a></li><li><a href=#latency>Latency</a></li></ul></li><li><a href=#routed-communication>Routed communication</a><ul><li><a href=#throughput-1>Throughput</a></li><li><a href=#latency-1>Latency</a></li></ul></li></ul></nav></div></div><main class="col-12 col-md-9 col-xl-8 py-md-3 pl-md-5 ato-content ato-docs"><h1 class=ato-title>Zenoh performance: a stroll in Rust async wonderland</h1><p class=ato-date>13 July 2021 -- Paris.</p><p>Since its very first public release, zenoh provided impressive and easily accessible performances (see <strong><a href=https://zenoh.io/blog/2020-06-29-zenoh-tidings/>here</a></strong>).
But instead of resting on laurels, the zenoh team has been relentlessly working on further improving them.</p><p>As a result of this work, we are happy to announce that zenoh delivers at least twice the performances than before:</p><ul><li>more than <strong>3.5M msg/s</strong> with 8 bytes payload,</li><li>more than <strong>45 Gb/s</strong> with 1 Megabyte payload,</li><li>a latency as little as <strong>35 µsec</strong> in backlogged scenarios.</li></ul><p>The reminder of this post will take you through the journey of zenoh profiling along with the nuts and bolts of Rust async programming.
If you are unfamiliar with Rust and you are just interested in the results, you can jump directly <strong><a href=#looking-at-the-results>here</a></strong>.</p><hr><h1 id=getting-ready>Getting ready</h1><p>As we previously wrote in this <strong><a href=https://zenoh.io/blog/2020-06-29-zenoh-tidings/>blog post</a></strong>, zenoh is purely written in <strong><a href=https://www.rust-lang.org/>Rust</a></strong> and leverages the <strong><a href=https://async.rs/>async</a></strong> features to achieve high performance and scalability.</p><p>Even though initial zenoh performances were already quite good, we weren’t completely happy about them. Some numbers didn’t sum up as expected and we were very puzzled about it: we knew that zenoh could deliver more. We had only to discover what was preventing us from getting there. So, during the last few months we have been relentlessly profiling zenoh and looking into its most deep and intimate internals.</p><p>The very first thing we did was to properly prepare our testing environment in such a way to get reproducible results. This is very important when profiling your code otherwise you risk to walk down the wrong path: there are plenty of external factors that may impact the performance of the code. If you are about to profile your code, we highly recommend you to follow this <strong><a href=https://easyperf.net/blog/2019/08/02/Perf-measurement-environment-on-Linux>guide</a></strong> that summarizes very well how to properly setup a Linux environment and how to get consistent results out of it.</p><p>The second thing was to have a thorough read of <strong><a href=https://nnethercote.github.io/perf-book/title-page.html>The Rust Performance Book</a></strong>. If you are developing in Rust like us, we recommend you to go through it since we found it really insightful for what concerns performance tips and tricks along with profiling techniques in Rust.
Another nice reference on how to write performant code in Rust can be found <strong><a href=http://likebike.com/posts/How_To_Write_Fast_Rust_Code.html>here</a></strong>.</p><h1 id=finding-the-hotspots>Finding the hotspots</h1><p>We started with identifying the hotspots in zenoh by generating flame-graphs with this <strong><a href=https://github.com/flamegraph-rs/flamegraph>tool</a></strong>. We were confident that flame-graphs were a good way to visualize which part of the code takes most of the time in zenoh. We were wrong.</p><p>We couldn’t see any function taking a substantial amount of time to justify the performance mismatch we were observing. In addition, async was making the flame-graph quite difficult to read because of the async scheduler and future executor appearing almost everywhere in the graph. So, we changed the profiling tool and we started using <strong><a href=https://perf.wiki.kernel.org/index.php/Main_Page>perf</a></strong> which provided, at least for us, a more clear view on the hotspots: notably on serialization and deserialization.</p><p>We improved our serializer and deserializer implementation and the synthetic benchmarks immediately improved by roughly 100%. However, that improvement didn’t reflect in the throughput tests. Nothing had changed. We were more puzzled than before.</p><h1 id=heap-or-not-to-heap-stack-is-the-problem>Heap or not to heap? Stack is the problem</h1><p>Then we started looking into memory allocations. Since the beginning of zenoh, we have been very careful to avoid heap allocations in the critical path. We used <strong><a href=https://www.valgrind.org/>Valgrind</a></strong> to double check if that was still the case and yes, it was: we didn’t observe unnecessary allocations nor suspicious high cache miss rates.</p><p>So, if it’s not the heap, it might be the stack. But how to see how deep the stack is? Especially when operating with async? Luckily for us, there is a very useful Rust compilation flag (available only in Rust nightly) to verify how big a data structure is and its cache alignment. It is sufficient to build zenoh (or any Rust code) with:</p><div class=highlight><pre style=background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh>$ <span style=color:#033>RUSTFLAGS</span><span style=color:#555>=</span>-Zprint-type-sizes cargo build --release
</code></pre></div><p>In addition to the usual Cargo output, each data structure including async futures is printed out with the corresponding size and cache alignment. An examples of the generated output for the zenoh data message Rust struct is:</p><div class=highlight><pre style=background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh>print-type-size type: <span style=color:#c30>`</span>net::protocol::proto::msg::Data<span style=color:#c30>`</span>: <span style=color:#f60>304</span> bytes, alignment: <span style=color:#f60>8</span> bytes
print-type-size     field <span style=color:#c30>`</span>.key<span style=color:#c30>`</span>: <span style=color:#f60>40</span> bytes
print-type-size     field <span style=color:#c30>`</span>.data_info<span style=color:#c30>`</span>: <span style=color:#f60>168</span> bytes
print-type-size     field <span style=color:#c30>`</span>.payload<span style=color:#c30>`</span>: <span style=color:#f60>96</span> bytes
</code></pre></div><p>And here comes the bitter discovery. These async futures, once compiled, were taking a few tens of KBs on the stack. These futures are called every time a message needs to be sent over the network. Unsurprisingly at this stage, we realized that we were putting too much pressure on the memory due to a stack too deep and large.
Async libraries and runtime were doing their job correctly, they were putting on the stack everything that was needed in order to have a proper asynchronous environment. The problem was that we used async code too extensively in zenoh, mainly driven by its great simplicity and superb ergonomics.</p><p>So, we started a deep dive into zenoh internals and did some introspection on how to tackle the problem. We like async, it provides great flexibility and scalability properties to zenoh and we didn’t want to let it go. The final solution was to isolate the async code in specific parts of the code, especially the one interacting with the network, and to move some other parts to the standard sync library. As a result, zenoh has now a very balanced mix of sync and async code that takes the best of both worlds. This allowed us to drastically reduce the stack size of some critical async futures which immediately reflected in a massive performance boost as described below.</p><hr><h1 id=looking-at-the-results>Looking at the results</h1><p>Throughput and latency tests are provided as examples in the main zenoh distribution. So, you can check what we actually used to get our throughput and latency results and replicate it yourself!</p><p>In the following we are going to show the throughput and latency results for both peer-to-peer and routed communications. To see the communication models supported by zenoh, please refer to the <strong><a href=https://zenoh.io/docs/getting-started/key-concepts/>documentation</a></strong>.</p><p>All the tests below are run on three of our workstations equipped with an AMD Ryzen 5800x, 32 GB of RAM, connected through a 100Gb Ethernet connection, and configured according to this <strong><a href=https://easyperf.net/blog/2019/08/02/Perf-measurement-environment-on-Linux>guide</a></strong>.</p><h2 id=peer-to-peer-communication>Peer-to-peer communication</h2><p>In the peer-to-peer communication test, we consider two peers that directly communicate with each other, that is without passing through an intermediate node.</p><h3 id=throughput>Throughput</h3><p>To build and run the p2p throughput tests just follow the instruction below:</p><div class=highlight><pre style=background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh>$ git clone https://github.com/eclipse-zenoh/zenoh.git
$ <span style=color:#366>cd</span> zenoh
$ cargo build --release --all-targets

<span style=color:#09f;font-style:italic># ---- zenoh-net test ----</span>
<span style=color:#09f;font-style:italic># run the zenoh-net subscriber</span>
$ ./target/release/examples/zn_sub_thr

<span style=color:#09f;font-style:italic># run the zenoh-net publisher with &lt;payload size&gt; (1024 below)</span>
$ ./target/release/examples/zn_pub_thr <span style=color:#f60>1024</span>

<span style=color:#09f;font-style:italic># ---- zenoh test ----</span>
<span style=color:#09f;font-style:italic># run the zenoh subscriber</span>
$ ./target/release/examples/z_sub_thr

<span style=color:#09f;font-style:italic># run the zenoh publisher with &lt;payload size&gt; (1024 below)</span>
$ ./target/release/examples/z_put_thr <span style=color:#f60>1024</span>
</code></pre></div><p>In this test, one workstation runs the publisher while a separate one runs the subscriber.
The figure below shows (in log scale) the number of messages per second for different payloads: from <strong>8 bytes</strong> to <strong>1 GiB</strong>.</p><p>As you can see, <strong>zenoh-net API</strong> delivers more than <strong>3.5M msg/s</strong> with a <strong>8 bytes payload</strong>.
At the same time, <strong>zenoh API</strong> delivers <strong>2M msg/s</strong>.</p><p><img src=../../img/blog-zenoh-performance-async-sync/p2p_msgs_api_log.png alt=msg-sec></p><p>The figure below shows (in log scale) the results in terms of throughput (bit/s) delivered at API level. We also report the throughput obtained with iperf on the same 100GbE connection as reference baseline: <strong>60 Gb/s</strong>.</p><p><img src=../../img/blog-zenoh-performance-async-sync/p2p_gbps_api_log.png alt=msg-sec></p><p>As it can be noticed, a <strong>100 Mb/s</strong> connection is already saturated by zenoh-net and zenoh with a payload as little as <strong>8 bytes</strong>.
A <strong>1 Gb/s</strong> connection is then saturated with a payload of <strong>32</strong> and <strong>64 bytes</strong> for zenoh-net and zenoh, respectively.
A payload of <strong>512</strong> and <strong>1024 bytes</strong> is then sufficient for zenoh-net and zenoh to saturate a <strong>10 Gb/s</strong> connection.
Finally, payloads larger than <strong>128 KB</strong> suffice to saturate a <strong>40 Gb/s</strong> connection.</p><h3 id=latency>Latency</h3><p>Throughput figures are very nice, but about latency? To run the p2p latency tests just follow the instructions below:</p><div class=highlight><pre style=background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=color:#09f;font-style:italic># ---- zenoh-net test ----</span>
<span style=color:#09f;font-style:italic># run the zenoh-net pong</span>
$ ./target/release/examples/zn_pong

<span style=color:#09f;font-style:italic># run the zenoh-net ping</span>
$ ./target/release/examples/zn_ping

<span style=color:#09f;font-style:italic># ---- zenoh test ----</span>
<span style=color:#09f;font-style:italic># run the zenoh pong</span>
$ ./target/release/examples/z_pong

<span style=color:#09f;font-style:italic># run the zenoh ping</span>
$ ./target/release/examples/z_ping
</code></pre></div><p>With latency is necessary to clarify one very important aspect: latency depends on the load of the system. As you can see from the figure below, as the number of messages per second increases, latency actually decreases. This is due to the fact that when messages are sent at a low rate, the processes are more likely to be descheduled by the operating system. This operation adds additional latency since the processes need to be rescheduled when messages are sent and received. This is true for both zenoh and the classical ping, which is reported as a reference baseline for latency.</p><p>The x axis of the figure below shows the number of messages that we configured to be sent in one second, from 1 to 1 million and beyond.
The inf case represents the scenario where messages are sent back-to-back as fast as possible.
In such a backlogged scenario, we can see that zenoh latency is as little as <strong>35 µsec</strong> for both zenoh-net and zenoh APIs. The payload size is <strong>64 bytes</strong>, the same as standard ICMP.</p><p><img src=../../img/blog-zenoh-performance-async-sync/p2p_latency_api.png alt=msg-sec></p><h2 id=routed-communication>Routed communication</h2><p>In the router communication test, we consider two clients that communicate with each other through an intermediate node: the zenoh router.</p><h3 id=throughput-1>Throughput</h3><p>To run the routed throughput tests just follow the instruction below:</p><div class=highlight><pre style=background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=color:#09f;font-style:italic># ---- zenoh-net test ----</span>
<span style=color:#09f;font-style:italic># run the zenoh router</span>
$ ./target/release/zenohd

<span style=color:#09f;font-style:italic># run the zenoh-net subscriber</span>
$ ./target/release/examples/zn_sub_thr -m client

<span style=color:#09f;font-style:italic># run the zenoh-net publisher with &lt;payload size&gt; (1024 below)</span>
$ ./target/release/examples/zn_pub_thr <span style=color:#f60>1024</span> -m client

<span style=color:#09f;font-style:italic># ---- zenoh test ----</span>
<span style=color:#09f;font-style:italic># run the zenoh router</span>
$ ./target/release/zenohd

<span style=color:#09f;font-style:italic># run the zenoh subscriber</span>
$ ./target/release/examples/z_sub_thr -m client

<span style=color:#09f;font-style:italic># run the zenoh publisher with &lt;payload size&gt; (1024 below)</span>
$ ./target/release/examples/z_put_thr <span style=color:#f60>1024</span> -m client
</code></pre></div><p>In this test, one workstation runs the publisher, one runs the router and a third one runs the subscriber.
The figure below shows (in log scale) the number of messages per second for different payloads: from <strong>8 bytes</strong> to <strong>1GiB</strong>.</p><p><img src=../../img/blog-zenoh-performance-async-sync/rtr_msgs_api_log.png alt=msg-sec></p><p>As you can see, zenoh-net API delivers <strong>3M msg/s</strong> with a <strong>8 bytes</strong> payload. At the same time, zenoh API delivers <strong>1.8M msg/s</strong>.
The figure below shows (in log scale) the same results in terms of throughput (bit/s) delivered at API level.</p><p><img src=../../img/blog-zenoh-performance-async-sync/rtr_gbps_api_log.png alt=msg-sec></p><p>As it can be noticed, a <strong>100 Mb/s</strong> connection is still saturated by zenoh-net and zenoh with a payload as little as <strong>8 bytes</strong>.
A <strong>1 Gb/s</strong> connection is then saturated with a payload of <strong>64 bytes</strong> for zenoh-net and zenoh.
A payload of <strong>1024 bytes</strong> is then sufficient for both zenoh-net and zenoh to saturate a <strong>10 Gb/s</strong> connection.
Finally, larger payloads are forwarded at <strong>20-30 Gb/s</strong>.</p><h3 id=latency-1>Latency</h3><p>To run the routed latency tests just follow the instructions below:</p><div class=highlight><pre style=background-color:#f0f3f3;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=color:#09f;font-style:italic># ---- zenoh-net test ----</span>
<span style=color:#09f;font-style:italic># run the zenoh router</span>
$ ./target/release/zenohd

<span style=color:#09f;font-style:italic># run the zenoh-net subscriber</span>
$ ./target/release/examples/zn_pong -m client

<span style=color:#09f;font-style:italic># run the zenoh-net publisher with &lt;payload size&gt; (1024 below)</span>
$ ./target/release/examples/zn_ping -m client

<span style=color:#09f;font-style:italic># ---- zenoh test ----</span>
<span style=color:#09f;font-style:italic># run the zenoh router</span>
$ ./target/release/zenohd

<span style=color:#09f;font-style:italic># run the zenoh subscriber</span>
$ ./target/release/examples/z_pong -m client

<span style=color:#09f;font-style:italic># run the zenoh publisher with &lt;payload size&gt; (1024 below)</span>
$ ./target/release/examples/z_ping -m client
</code></pre></div><p>In the routed test, latency is double than the p2p test: <strong>70 µs</strong>.
This is due to the fact that an additional network hop, i.e. the router, has been introduced between the two clients.
Nevertheless, it can be noticed that the router does not add any noticeable latency to the overall communication, being the latency driven mainly by the number of hops.
The payload size is still <strong>64 bytes</strong>.</p><p><img src=../../img/blog-zenoh-performance-async-sync/rtr_latency_api.png alt=msg-sec></p><hr><h1 id=conclusions>Conclusions</h1><p>Summarizing, recent work makes zenoh capable to deliver over <strong>3.5M msg/s</strong> for small messages, over <strong>45 Gb/s</strong> for large messages, and a latency as little as <strong>35 µsec</strong>.</p><p>This has been possible thanks to the careful redesign of some core parts of zenoh that led to a more balanced mix of synchronous and asynchronous code.
Although the results are already very remarkable, rest assured, our journey towards better performance doesn’t end here!</p><p>This blog post is just a very important milestone for zenoh, not the finishing line.</p><p><a href=https://github.com/Mallets/><strong>&ndash;LC</strong></a></p><div class=ato-next><b>Next up</b>: <a href=/blog/2021-07-05-zenoh-overhead/>Zenoh overhead: a story from our community</a></div></main></div></div><footer class="ato-footer text-muted"><div class="container-fluid p-6 p-md-5"><div class=row><div class=col-md-2><h5>Eclipse Incubation</h5><p><img src=../../img/eclipse-incubation.png style=width:100px></p><p>Eclipse zenoh &trade; is an incubating project under the Eclipse Foundation.</p></div><div class=col-md-2><h5>More Information</h5><p><a href=https://www.eclipse.org/legal target=_blank>Legal</a></p><p><a href=https://www.eclipse.org/legal/privacy.php target=_blank>Privacy policy</a></p><p><a href=https://www.eclipse.org/legal/termsofuse.php target=_blank>Terms of use</a></p><p><a href=https://www.eclipse.org/legal/copyright.php target=_blank>Copyright</a></p><p><a href=https://www.eclipse.org/security/ target=_blank>Report a security issue</a></p><p><a href=https://www.eclipse.org/legal/epl-2.0/ target=_blank>Eclipse Public License 2.0</a></p><p><a href=https://www.apache.org/licenses/LICENSE-2.0 target=_blank>Apache License 2.0</a></p><p><a href=https://www.eclipse.org/ target=_blank>Eclipse Foundation</a></p></div><div class=col-md-2><h5>Sponsored by:</h5><p><a href=https://www.eclipse.org target=_blank><img src=../../img/eclipse-foundation.svg style=width:120px></a></p><p><a href=https://www.adlinktech.com target=_blank><img src=https://cdn.adlinktech.com/webupd/en/Upload/logo.png style=width:120px></a></p><p><a href=https://www.futurewei.com target=_blank><img src=../../img/futurewei-logo.png style=width:120px></a></p></div><div class=col-md-2><h5>Follow us</h5><p><a href=https://github.com/eclipse-zenoh/zenoh><i class="fa fa-github" aria-hidden=true></i>GitHub</a></p><p><a href=https://gitter.im/atolab/zenoh><i class="fa fa fa-comments-o" aria-hidden=true></i>Gitter</a></p><p><a href=../../docs/overview/><i class="fa fa-info-circle" aria-hidden=true></i>About</a></p></div><div class=col-md-2><p><img src=../../img/zenoh-dragon.png style=width:45px></p><p>Eclipse zenoh &trade; is free, open source and always will be.</p><p>Copyright &copy 2021 Eclipse Foundation</p><p>Build with <a href=https://gohugo.io/ target=_blank>HUGO</a></p><p>Theme inspired from: <a href=https://tokio.rs/ target=_blank>Tokio website theme</a></p></div></div></div></footer><script src=https://ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js integrity=sha384-3ceskX3iaEnIogmQchP8opvBy3Mi7Ce34nWjpBIwVTHfGYWQS9jwHDVRnpKKHJg7 crossorigin=anonymous></script><script src=https://cdnjs.cloudflare.com/ajax/libs/tether/1.3.7/js/tether.min.js integrity=sha384-XTs3FgkjiBgo8qjEjBk0tGmf3wPrWtA6coPfQDfFEY8AnYJwjalXCiosYRBIBZX8 crossorigin=anonymous></script><script src=../../js/bootstrap.min.js></script><script src=../../js/highlight.js></script><script>$(function(){$("pre code").each(function(i,block){if(block.className.indexOf('language-rust')>=0){var new_content='';var lines=block.textContent.split('\n');for(var i=0;i<lines.length;i++){if(lines[i].indexOf('# ')==0||lines[i]=='#'){continue}
new_content+=lines[i].trimRight()+'\n';}
block.textContent=new_content.replace(/\n\n\n/g,"\n\n").trimRight();}
hljs.highlightBlock(block);});});</script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js></script><script type=text/javascript>docsearch({apiKey:'d7b5b785798fe748621bcaa8301a2201',indexName:'zenoh',inputSelector:'#search-input',debug:false});</script><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');ga('create','UA-41082619-2','auto');ga('send','pageview');}</script></body></html>